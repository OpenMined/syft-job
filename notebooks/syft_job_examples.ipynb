{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syft Job Submission System - Examples\n",
    "\n",
    "This notebook demonstrates the **simplified bash-script-only** syft-job system.\n",
    "\n",
    "## Key Features:\n",
    "- ‚úÖ **Bash-script driven** - Users provide custom bash scripts\n",
    "- ‚úÖ **Environment variable injection** - CODE_DIR, OUTPUT_DIR, TRAIN, TEST, etc.\n",
    "- ‚úÖ **Local & syft:// URL support** - Works with both local paths and syft URLs\n",
    "- ‚úÖ **Simple job structure** - Each job creates config.yaml and run.sh\n",
    "- ‚úÖ **Multi-language support** - Python, Go, or any language via bash\n",
    "\n",
    "## Job Structure Created:\n",
    "```\n",
    "job-{uuid}/\n",
    "‚îú‚îÄ‚îÄ config.yaml    # Job configuration\n",
    "‚îú‚îÄ‚îÄ run.sh         # Your bash script (processed)\n",
    "‚îú‚îÄ‚îÄ inputs/        # Resolved input data\n",
    "‚îî‚îÄ‚îÄ outputs/       # Job output files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Add src to path so we can import syft_job\n",
    "sys.path.insert(0, './src')\n",
    "import syft_job as sj\n",
    "\n",
    "print(\"üéâ Syft Job System - Bash-Script Driven\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Let's create some sample data and code directories for our examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create sample data files for testing.\"\"\"\n",
    "    data_dir = Path(\"./sample_data\")\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create train data\n",
    "    train_data = data_dir / \"train.csv\" \n",
    "    train_data.write_text(\"id,feature1,feature2,label\\n1,0.1,0.2,A\\n2,0.3,0.4,B\\n3,0.5,0.6,A\\n\")\n",
    "    \n",
    "    # Create test data\n",
    "    test_data = data_dir / \"test.csv\"\n",
    "    test_data.write_text(\"id,feature1,feature2\\n4,0.7,0.8\\n5,0.9,1.0\\n\")\n",
    "    \n",
    "    print(f\"üìÅ Created sample data in: {data_dir}\")\n",
    "    return str(data_dir)\n",
    "\n",
    "def create_python_code():\n",
    "    \"\"\"Create a simple Python analysis script.\"\"\"\n",
    "    code_dir = Path(\"./sample_code/python_analysis\")\n",
    "    code_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create the main Python script\n",
    "    main_py = code_dir / \"analysis.py\"\n",
    "    main_py.write_text(\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"[ANALYSIS] Starting Python data analysis...\")\n",
    "print(f\"[ANALYSIS] Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Read environment variables for inputs\n",
    "train_file = os.environ.get(\"TRAIN\", \"No TRAIN data\")\n",
    "test_file = os.environ.get(\"TEST\", \"No TEST data\")\n",
    "output_dir = os.environ.get(\"OUTPUT_DIR\", \"./outputs\")\n",
    "\n",
    "print(f\"[ANALYSIS] Train data: {train_file}\")\n",
    "print(f\"[ANALYSIS] Test data: {test_file}\")\n",
    "print(f\"[ANALYSIS] Output directory: {output_dir}\")\n",
    "\n",
    "# Read and process data\n",
    "results = {\"job_type\": \"python_analysis\", \"status\": \"completed\"}\n",
    "\n",
    "if os.path.exists(train_file):\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    results[\"train_rows\"] = len(train_data)\n",
    "    print(f\"[ANALYSIS] Loaded training data: {len(train_data)} rows\")\n",
    "    print(train_data.head())\n",
    "else:\n",
    "    results[\"train_rows\"] = 0\n",
    "\n",
    "if os.path.exists(test_file):\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    results[\"test_rows\"] = len(test_data)\n",
    "    print(f\"[ANALYSIS] Loaded test data: {len(test_data)} rows\")\n",
    "else:\n",
    "    results[\"test_rows\"] = 0\n",
    "\n",
    "# Write results\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir, \"analysis_results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"[ANALYSIS] Analysis complete! Results saved.\")\n",
    "\"\"\")\n",
    "    \n",
    "    # Create requirements.txt\n",
    "    requirements = code_dir / \"requirements.txt\"\n",
    "    requirements.write_text(\"pandas>=1.0.0\\n\")\n",
    "    \n",
    "    print(f\"üìÅ Created Python code in: {code_dir}\")\n",
    "    return str(code_dir)\n",
    "\n",
    "# Create sample data and code\n",
    "data_dir = create_sample_data()\n",
    "python_code_dir = create_python_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Python Job\n",
    "\n",
    "This example shows how to submit a Python analysis job with a custom bash script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Example 1: Python Analysis Job ===\")\n",
    "\n",
    "# Define our bash script for Python execution\n",
    "python_script = \"\"\"#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"[JOB] Starting Python analysis job...\"\n",
    "echo \"[JOB] Code directory: $CODE_DIR\"\n",
    "echo \"[JOB] Output directory: $OUTPUT_DIR\"\n",
    "\n",
    "# Install Python dependencies\n",
    "echo \"[JOB] Installing Python dependencies...\"\n",
    "if [ -f \"$CODE_DIR/requirements.txt\" ]; then\n",
    "    pip install -r \"$CODE_DIR/requirements.txt\"\n",
    "else\n",
    "    echo \"[JOB] No requirements.txt found, skipping dependency installation\"\n",
    "fi\n",
    "\n",
    "# Run the Python analysis\n",
    "echo \"[JOB] Running Python analysis script...\"\n",
    "python \"$CODE_DIR/analysis.py\"\n",
    "\n",
    "echo \"[JOB] Python job completed successfully!\"\n",
    "\"\"\"\n",
    "\n",
    "# Submit the job\n",
    "result = sj.submit_job(\n",
    "    name=\"Python Data Analysis\",\n",
    "    code=python_code_dir,  # Local path to code\n",
    "    run_script=python_script,  # Our custom bash script\n",
    "    inputs={\n",
    "        \"TRAIN\": f\"{data_dir}/train.csv\",  # Local path\n",
    "        \"TEST\": f\"{data_dir}/test.csv\"     # Local path  \n",
    "    },\n",
    "    job_dir=\"./jobs\",\n",
    "    sync=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Job Results:\")\n",
    "print(f\"   Job ID: {result.job_id}\")\n",
    "print(f\"   Status: {result.status}\")\n",
    "print(f\"   Duration: {result.duration:.2f}s\")\n",
    "\n",
    "if result.output:\n",
    "    print(f\"\\nüìú Job Output:\")\n",
    "    print(result.output)\n",
    "\n",
    "if result.artifacts:\n",
    "    print(f\"\\nüìÅ Artifacts created: {len(result.artifacts)} files\")\n",
    "    for artifact in result.artifacts:\n",
    "        print(f\"   - {artifact}\")\n",
    "\n",
    "python_job_id = result.job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Inline Bash Script Job\n",
    "\n",
    "This example demonstrates using inline bash scripts for simple data processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Example 2: Inline Bash Processing ===\")\n",
    "\n",
    "# Define an inline bash script for data processing\n",
    "bash_processing_script = \"\"\"#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"[BASH] Starting bash data processing...\"\n",
    "echo \"[BASH] Available data: $TRAIN\"\n",
    "echo \"[BASH] Output directory: $OUTPUT_DIR\"\n",
    "\n",
    "# Simple data processing with bash tools\n",
    "if [ -f \"$TRAIN\" ]; then\n",
    "    echo \"[BASH] Processing training data...\"\n",
    "    line_count=$(wc -l < \"$TRAIN\")\n",
    "    echo \"[BASH] Training data has $line_count lines\"\n",
    "    \n",
    "    # Create data summary\n",
    "    echo \"Data Processing Summary\" > \"$OUTPUT_DIR/summary.txt\"\n",
    "    echo \"======================\" >> \"$OUTPUT_DIR/summary.txt\"\n",
    "    echo \"Input file: $TRAIN\" >> \"$OUTPUT_DIR/summary.txt\"\n",
    "    echo \"Total lines: $line_count\" >> \"$OUTPUT_DIR/summary.txt\"\n",
    "    echo \"Processed at: $(date)\" >> \"$OUTPUT_DIR/summary.txt\"\n",
    "    \n",
    "    # Create a JSON result\n",
    "    echo '{\"type\": \"bash_processing\", \"status\": \"completed\", \"lines_processed\": '$line_count'}' > \"$OUTPUT_DIR/result.json\"\n",
    "else\n",
    "    echo \"[BASH] No training data found at: $TRAIN\"\n",
    "fi\n",
    "\n",
    "echo \"[BASH] Bash processing completed!\"\n",
    "\"\"\"\n",
    "\n",
    "# Submit the job\n",
    "result = sj.submit_job(\n",
    "    name=\"Bash Data Processing\",\n",
    "    code=data_dir,  # Use data directory as code directory\n",
    "    run_script=bash_processing_script,  # Inline bash script\n",
    "    inputs={\n",
    "        \"TRAIN\": f\"{data_dir}/train.csv\"\n",
    "    },\n",
    "    job_dir=\"./jobs\",\n",
    "    sync=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Job Results:\")\n",
    "print(f\"   Job ID: {result.job_id}\")\n",
    "print(f\"   Status: {result.status}\")\n",
    "print(f\"   Duration: {result.duration:.2f}s\")\n",
    "\n",
    "if result.output:\n",
    "    print(f\"\\nüìú Job Output:\")\n",
    "    print(result.output)\n",
    "\n",
    "bash_job_id = result.job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Multi-Language Support (Go)\n",
    "\n",
    "The system supports any language through custom bash scripts. Here's a Go example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Example 3: Go Programming Job ===\")\n",
    "\n",
    "# Create a simple Go program\n",
    "def create_go_code():\n",
    "    code_dir = Path(\"./sample_code/go_processor\")\n",
    "    code_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create main.go\n",
    "    main_go = code_dir / \"main.go\"\n",
    "    main_go.write_text(\"\"\"\n",
    "package main\n",
    "\n",
    "import (\n",
    "\t\"encoding/json\"\n",
    "\t\"fmt\"\n",
    "\t\"os\"\n",
    "\t\"path/filepath\"\n",
    "\t\"time\"\n",
    ")\n",
    "\n",
    "type Result struct {\n",
    "\tJobType   string    `json:\"job_type\"`\n",
    "\tStatus    string    `json:\"status\"`\n",
    "\tMessage   string    `json:\"message\"`\n",
    "\tTimestamp time.Time `json:\"timestamp\"`\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\tfmt.Println(\"[GO] Starting Go data processor...\")\n",
    "\t\n",
    "\t// Read environment variables\n",
    "\ttrainFile := os.Getenv(\"TRAIN\")\n",
    "\ttestFile := os.Getenv(\"TEST\")\n",
    "\toutputDir := os.Getenv(\"OUTPUT_DIR\")\n",
    "\t\n",
    "\tfmt.Printf(\"[GO] Train file: %s\\\\n\", trainFile)\n",
    "\tfmt.Printf(\"[GO] Test file: %s\\\\n\", testFile)\n",
    "\tfmt.Printf(\"[GO] Output dir: %s\\\\n\", outputDir)\n",
    "\t\n",
    "\t// Create output directory\n",
    "\tos.MkdirAll(outputDir, 0755)\n",
    "\t\n",
    "\t// Create result\n",
    "\tresult := Result{\n",
    "\t\tJobType:   \"go_processor\",\n",
    "\t\tStatus:    \"completed\",\n",
    "\t\tMessage:   \"Go data processing completed successfully\",\n",
    "\t\tTimestamp: time.Now(),\n",
    "\t}\n",
    "\t\n",
    "\t// Write result to JSON file\n",
    "\tresultFile := filepath.Join(outputDir, \"go_results.json\")\n",
    "\tfile, err := os.Create(resultFile)\n",
    "\tif err != nil {\n",
    "\t\tfmt.Printf(\"Error creating result file: %v\\\\n\", err)\n",
    "\t\treturn\n",
    "\t}\n",
    "\tdefer file.Close()\n",
    "\t\n",
    "\tencoder := json.NewEncoder(file)\n",
    "\tencoder.SetIndent(\"\", \"  \")\n",
    "\tif err := encoder.Encode(result); err != nil {\n",
    "\t\tfmt.Printf(\"Error writing result: %v\\\\n\", err)\n",
    "\t\treturn\n",
    "\t}\n",
    "\t\n",
    "\tfmt.Println(\"[GO] Processing complete! Results saved.\")\n",
    "}\n",
    "\"\"\")\n",
    "    \n",
    "    # Create go.mod\n",
    "    go_mod = code_dir / \"go.mod\"\n",
    "    go_mod.write_text(\"module go_processor\\n\\ngo 1.21\\n\")\n",
    "    \n",
    "    print(f\"üìÅ Created Go code in: {code_dir}\")\n",
    "    return str(code_dir)\n",
    "\n",
    "# Create Go code\n",
    "go_code_dir = create_go_code()\n",
    "\n",
    "# Define Go execution script\n",
    "go_script = \"\"\"#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"[JOB] Starting Go build and execution...\"\n",
    "echo \"[JOB] Code directory: $CODE_DIR\"\n",
    "echo \"[JOB] Output directory: $OUTPUT_DIR\"\n",
    "\n",
    "# Build the Go program\n",
    "echo \"[JOB] Building Go program...\"\n",
    "cd \"$CODE_DIR\"\n",
    "go build -o \"$OUTPUT_DIR/go_processor\" main.go\n",
    "\n",
    "# Run the Go program\n",
    "echo \"[JOB] Running Go program...\"\n",
    "\"$OUTPUT_DIR/go_processor\"\n",
    "\n",
    "echo \"[JOB] Go job completed successfully!\"\n",
    "\"\"\"\n",
    "\n",
    "# Submit the Go job\n",
    "result = sj.submit_job(\n",
    "    name=\"Go Data Processor\", \n",
    "    code=go_code_dir,\n",
    "    run_script=go_script,\n",
    "    inputs={\n",
    "        \"TRAIN\": f\"{data_dir}/train.csv\",\n",
    "        \"TEST\": f\"{data_dir}/test.csv\"\n",
    "    },\n",
    "    job_dir=\"./jobs\",\n",
    "    timeout=60,\n",
    "    sync=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Job Results:\")\n",
    "print(f\"   Job ID: {result.job_id}\")\n",
    "print(f\"   Status: {result.status}\")\n",
    "print(f\"   Duration: {result.duration:.2f}s\")\n",
    "\n",
    "if result.output:\n",
    "    print(f\"\\nüìú Job Output:\")\n",
    "    print(result.output)\n",
    "\n",
    "go_job_id = result.job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Batch Job Submission\n",
    "\n",
    "Submit multiple jobs at once using the batch functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Example 4: Batch Job Submission ===\")\n",
    "\n",
    "# Define a batch processing script\n",
    "batch_script = \"\"\"#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"[BATCH] Starting batch processing job...\"\n",
    "echo \"[BATCH] Job ID: $BATCH_ID\"\n",
    "echo \"[BATCH] Processing data: $TRAIN\"\n",
    "\n",
    "# Simple processing with bash tools\n",
    "if [ -f \"$TRAIN\" ]; then\n",
    "    line_count=$(wc -l < \"$TRAIN\")\n",
    "    echo \"[BATCH] Found $line_count lines in data file\"\n",
    "    \n",
    "    # Create batch result\n",
    "    echo '{\"batch_job\": \"'$BATCH_ID'\", \"lines_processed\": '$line_count', \"status\": \"completed\"}' > \"$OUTPUT_DIR/batch_result.json\"\n",
    "else\n",
    "    echo \"[BATCH] No data file found\"\n",
    "    echo '{\"batch_job\": \"'$BATCH_ID'\", \"status\": \"no_data\"}' > \"$OUTPUT_DIR/batch_result.json\"\n",
    "fi\n",
    "\n",
    "echo \"[BATCH] Batch job completed!\"\n",
    "\"\"\"\n",
    "\n",
    "# Create multiple batch jobs\n",
    "jobs = []\n",
    "for i in range(3):\n",
    "    jobs.append({\n",
    "        \"name\": f\"Batch Job {i+1}\",\n",
    "        \"code\": data_dir,  # Use data directory\n",
    "        \"run_script\": batch_script.replace(\"$BATCH_ID\", f\"batch_{i+1}\"),\n",
    "        \"inputs\": {\n",
    "            \"TRAIN\": f\"{data_dir}/train.csv\"\n",
    "        },\n",
    "        \"metadata\": {\"batch_index\": i}\n",
    "    })\n",
    "\n",
    "# Submit batch jobs\n",
    "results = sj.submit_batch_jobs(jobs, job_dir=\"./jobs\")\n",
    "\n",
    "print(f\"\\nüéØ Batch Results:\")\n",
    "print(f\"   Submitted {len(results)} batch jobs:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"   Job {i+1}: {result.job_id} - {result.status} ({result.duration:.2f}s)\")\n",
    "\n",
    "batch_job_ids = [r.job_id for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Job Workspaces\n",
    "\n",
    "Let's explore the job workspaces that were created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Job Workspace Inspection ===\")\n",
    "\n",
    "jobs_dir = Path(\"./jobs\")\n",
    "if jobs_dir.exists():\n",
    "    job_dirs = [d for d in jobs_dir.iterdir() if d.is_dir()]\n",
    "    print(f\"\\nüìÅ Found {len(job_dirs)} job workspaces:\")\n",
    "    \n",
    "    for job_dir in sorted(job_dirs, key=lambda p: p.stat().st_mtime):\n",
    "        print(f\"\\nüóÇÔ∏è  {job_dir.name}:\")\n",
    "        \n",
    "        # Show directory structure\n",
    "        for item in job_dir.iterdir():\n",
    "            if item.is_file():\n",
    "                if item.name == \"config.yaml\":\n",
    "                    print(f\"    üìÑ {item.name} (job configuration)\")\n",
    "                elif item.name == \"run.sh\":\n",
    "                    print(f\"    üìÑ {item.name} (bash script)\")\n",
    "                else:\n",
    "                    print(f\"    üìÑ {item.name}\")\n",
    "            elif item.is_dir():\n",
    "                if item.name == \"inputs\":\n",
    "                    input_files = list(item.glob(\"*\"))\n",
    "                    print(f\"    üìÅ {item.name}/ ({len(input_files)} files)\")\n",
    "                elif item.name == \"outputs\":\n",
    "                    output_files = list(item.glob(\"*\"))\n",
    "                    print(f\"    üìÅ {item.name}/ ({len(output_files)} files)\")\n",
    "                    for output_file in output_files:\n",
    "                        print(f\"       üìÑ {output_file.name}\")\n",
    "                else:\n",
    "                    print(f\"    üìÅ {item.name}/\")\n",
    "else:\n",
    "    print(\"No jobs directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Generated Files\n",
    "\n",
    "Let's examine the config.yaml and run.sh files that were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Generated Job Files ===\")\n",
    "\n",
    "jobs_dir = Path(\"./jobs\")\n",
    "if jobs_dir.exists():\n",
    "    job_dirs = [d for d in jobs_dir.iterdir() if d.is_dir()]\n",
    "    if job_dirs:\n",
    "        # Show the most recent job\n",
    "        latest_job = max(job_dirs, key=lambda p: p.stat().st_mtime)\n",
    "        print(f\"\\nüìã Inspecting latest job: {latest_job.name}\")\n",
    "        \n",
    "        # Show config.yaml\n",
    "        config_file = latest_job / \"config.yaml\"\n",
    "        if config_file.exists():\n",
    "            print(f\"\\nüìÑ config.yaml:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(config_file.read_text())\n",
    "        \n",
    "        # Show run.sh (first 20 lines to keep it manageable)\n",
    "        run_file = latest_job / \"run.sh\" \n",
    "        if run_file.exists():\n",
    "            print(f\"\\nüìÑ run.sh (first 20 lines):\")\n",
    "            print(\"-\" * 40)\n",
    "            lines = run_file.read_text().split('\\n')\n",
    "            for i, line in enumerate(lines[:20]):\n",
    "                print(f\"{i+1:2d}: {line}\")\n",
    "            if len(lines) > 20:\n",
    "                print(f\"... ({len(lines) - 20} more lines)\")\n",
    "    else:\n",
    "        print(\"No job directories found\")\n",
    "else:\n",
    "    print(\"No jobs directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the key features of the simplified syft-job system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ Syft Job System Examples Complete!\")\n",
    "print(\"\\nüìñ Key Features Demonstrated:\")\n",
    "print(\"   ‚úÖ Bash-script driven execution\")\n",
    "print(\"   ‚úÖ Environment variable injection (CODE_DIR, OUTPUT_DIR, TRAIN, TEST)\")\n",
    "print(\"   ‚úÖ Multi-language support (Python, Go, Bash)\")\n",
    "print(\"   ‚úÖ Local path and syft:// URL support\")\n",
    "print(\"   ‚úÖ Batch job submission\")\n",
    "print(\"   ‚úÖ Simple job workspace structure\")\n",
    "\n",
    "print(\"\\nüí° Basic Usage Pattern:\")\n",
    "print(\"\"\"```python\n",
    "import syft_job as sj\n",
    "\n",
    "# Define your bash script\n",
    "script = '''#!/bin/bash\n",
    "set -e\n",
    "# Install dependencies\n",
    "pip install -r \"$CODE_DIR/requirements.txt\"\n",
    "# Run your code  \n",
    "python \"$CODE_DIR/my_script.py\"\n",
    "'''\n",
    "\n",
    "# Submit the job\n",
    "result = sj.submit_job(\n",
    "    name=\"My Job\",\n",
    "    code=\"./my_code\",\n",
    "    run_script=script,\n",
    "    inputs={\"DATA\": \"./data.csv\"},\n",
    "    job_dir=\"./jobs\"\n",
    ")\n",
    "```\"\"\")\n",
    "\n",
    "print(\"\\nüìÅ Each job creates a workspace with:\")\n",
    "print(\"   üìÑ config.yaml - Job configuration\")\n",
    "print(\"   üìÑ run.sh - Your processed bash script\")\n",
    "print(\"   üìÅ inputs/ - Resolved input data files\")\n",
    "print(\"   üìÅ outputs/ - Job output files\")\n",
    "\n",
    "print(\"\\nüîß Environment Variables Available in Scripts:\")\n",
    "print(\"   ‚Ä¢ CODE_DIR - Path to your code directory\")\n",
    "print(\"   ‚Ä¢ OUTPUT_DIR - Path to job outputs directory\")\n",
    "print(\"   ‚Ä¢ {INPUT_NAME} - Paths to your input files (TRAIN, TEST, DATA, etc.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup (optional)\n",
    "print(\"\\nüßπ Cleanup (run this cell to remove example files):\")\n",
    "print(\"Uncomment the lines below to clean up the example files created:\")\n",
    "print()\n",
    "\n",
    "# Uncomment these lines to clean up:\n",
    "# shutil.rmtree(\"./sample_data\", ignore_errors=True)\n",
    "# shutil.rmtree(\"./sample_code\", ignore_errors=True)\n",
    "# shutil.rmtree(\"./jobs\", ignore_errors=True)\n",
    "# print(\"‚úÖ Cleanup completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}